{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wsb = pd.read_csv('r_wsb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RH sent me a BS email back about the support ticket I sent them a while ago\n",
      "TBT 6/18 20c\n",
      "Start of commodity super cycle - $MT, $FCX, $XOM and many others now boarding the üöÄ\n",
      "WSBGod - Searching For The Truth\n",
      "$UBS lazy Saturday morning half-ass DD\n",
      "‚ö°Ô∏èTSLA GANG ‚ö°Ô∏èDouble Bottom &amp; Possible Breakout BTFD üöÄ ‚òÄÔ∏è\n",
      "WEEDSTOCKS WENT BURR\n",
      "Wall Street Week Ahead for the trading week beginning February 15th, 2021\n",
      "NOT EVERY PLAY IS A SHORT SQUEEZE PLAY üöÄüöÄ ü¶ç ü¶ç üåïüåï\n",
      "It wasn't just RH, all brokerage firms did the same thing.\n",
      "The stock market is a pendulum\n",
      "Let's talk about LoanDepot (LDi) and it's potential upside movement in the next few weeks.\n",
      "DD: Cloudflare (NET) is going to continue its strong outperformance. Buy the dip\n",
      "GME; when diamonds break (missing another 25k loss expired last week)\n",
      "COTY dd - Makeup Never Dies\n",
      "Most Anticipated Earnings Releases for the week beginning February 15th, 2021\n",
      "You might consider entering $ATVI\n",
      "AMD and Intel DD\n",
      "Summary of all $BB (BlackBerry) fundamentals/news\n",
      "UWMC: a powder keg with over 100% of float shorted\n",
      "Keith Gill / DeepFuckingValue Tribute\n",
      "AMD Technical Analysis\n",
      "Analysis of the DJ average growth and the sub prime mortgage crisis of 2008 and how the current market isn't overvalued.üñïüåàüêª\n",
      "$TSLA is positioned for a massive reversal\n",
      "Here‚Äôs to all the Karen‚Äôs in the world. GME 20K to 1.35 million.\n",
      "How to beat CNBC\n",
      "Why not a bubble?\n",
      "Smuckers - SJM DD\n",
      "Why cant we post DD on Companies in the Cripto space?\n",
      "Full 401k YOLO into the $APHA merger arbitrage play\n",
      "Big Data Dating: Palantir partnering with Bumble. $BMBL $PLTR\n",
      "$CRSP down 23%??? Apes Assemble ü¶ßü¶ç\n",
      "Virpax Pharmaceuticals IPO? Sounds iffy...\n",
      "CERENCE: A REAL DD YOU DO NOT WANT TO MISS!\n",
      "Question. Is anyone else being followed...?\n",
      "Can't Stop Won't Stop BRAINSTOP üß†üõë\n",
      "How would you protect your money if you became a multi millionaire overnight?\n",
      "Under Morgan's new system, an overweight rating means the analyst believes the stock will produce a greater total return (appreciation plus any dividend income) than the average return expected of others covered in its industry over the next 12 to 18 months. Guess they view QS the same as I do! üëäüèº\n",
      "Autist Rich Asian: Ape bought $10M of GME near its peak ($8M Loss)\n",
      "SCR - Score Media and Gaming\n",
      "A Good Point About the Squeeze and GME\n",
      "January (WITH CAPTIONS lmao)\n",
      "I'm losing alot of money..\n",
      "The Next Pandemic: Paper Portnoy Syndrome üßªüëê\n",
      "I am SHOCKED that paper handing is going on in this sub\n",
      "There is no sell.\n",
      "$RKT ready for take-off...\n",
      "one year ago today i started investing in stocks, happy to say i‚Äôve made a 102% return as of today, hopefully i can pull this off every year i‚Äôll be rich!!\n",
      "GME gains! Still holding my shares invested 10 thousand into GME calls, sold them and bought shares. Still holdingüôåüèΩüíéüöÄüöÄ\n",
      "January\n",
      "‚ÄúWhat to do if you lost money on GameStop, AMC, or other ‚Äòmeme stocks‚Äô ‚Äú\n",
      "Mods can we discuss the no &lt;1B rule. that was when we had 1.5M people with 9M users it's time to discuss updating it.\n",
      "DFV vs Melvin and Robinhood live\n",
      "A lot of ITM options does not mean gamma squeeze. Gamma squeezes are not common.\n",
      "Why no GME daily?\n",
      "Remember- GEE EM EE is only where it is because of blatant market manipulation.\n",
      "People thinking there going to find the next GME and AMC\n",
      "What the VIX is happening?\n",
      "SENS makes sense to me.\n",
      "Robinhood's 1099 are crap\n",
      "Meet the degenerates ü•Ç\n",
      "From $2.8 million in TLRY yesterday to $1.1 million today, we all know its going to $100+ sooner than you think\n",
      "2 weeks ago I felt like this sub was my new home, not now.\n",
      "Non-YOLO options questions because I'm r-tard degenerate newb cunt\n",
      "$PSTH Raising Target\n",
      "Reading into Blackberry‚Äôs CEO\n",
      "Investing the stock market. I mean literally, there's a company that owns the exchange.\n",
      "$ET. Some DD from a new guy.\n",
      "Why RAVI is the best indicator for effortless 2-8% tendies 3 times a day\n",
      "CureVac (CVAC) making the coronavirus vaccine for Europoors and beyond\n",
      "First trade of my life: Buy GME at $90, sell at $420.69. Am I doing it right?\n",
      "Roblox Listing Coming In March Thoughts?\n",
      "Wallstreetbets I fucking love you\n",
      "Let‚Äôs talk taxes! I would hate for a fellow WSB member to get in trouble with Uncle Sam!\n",
      "Dear CNBC\n",
      "I can't believe I have to say this, but a lot of people need to hear it: THE STOCK MARKET ISN'T FAIR\n",
      "Which weed ETF will provide most exposure to US market if weed becomes legalized in America?\n",
      "I still live with my parents so I decided to yolo 80k üöÄüöÄüöÄüöÄüöÄ S-O-S or S-O-YES üöÄüöÄüöÄüöÄ\n",
      "We are so close to greatness\n",
      "What happened with weed you ask?\n",
      "Cloudflare $NET has made my dick hard for more than 4 hours\n",
      "Do you think lithium mining is a good bet?\n",
      "Stop investing in companies that are losing money!\n",
      "Potential strategy - investing primarily in businesses that live in industries with a great deal of regulation.\n",
      "The Tendieman will guide us to Valhalla\n",
      "PLTR DD - brain cells required if you are an ape!\n",
      "Continental Automotive has a lot of potential for a long term play (if I knew how to do emojis I would put them here)\n",
      "Why people don't understand HYLN\n",
      "GME price action DD: making higher lows and turning an ancient resistance into support\n",
      "$ZOM 's smart play\n",
      "Novo Nordisk (NVO) - Boomer safety stock with tendie potential (DD... ish)\n",
      "$OPEN - DISRUPTING THE REAL ESTATE INDUSTRY üöÄüöÄ\n",
      "Thoughts on Luckin Coffee (LKNCY)\n",
      "Scorpio Tankers YOLO Update 2/12/2021 üöÄüöÄ\n",
      "Weekend Discussion Thread for the Weekend of February 12, 2021\n",
      "The GME shit in summary\n",
      "Why trading options if you can increase your leverage simply by buying more stocks?\n",
      "GME Hold and GME Paying their Debts.\n",
      "GameStop Integrating a Digital Currency Rewards Program??\n",
      "A bear case for MVIS (DD)\n"
     ]
    }
   ],
   "source": [
    "for i in df_wsb['title']:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add only the entity recognizer to the new blank pipeline\n",
    "nlp = spacy.blank(\"en\")\n",
    "ruler = nlp.create_pipe('entity_ruler')\n",
    "nlp.add_pipe(ruler)\n",
    "\n",
    "patterns = [{'label':'ORG','id':'BB','pattern':'BB'},\n",
    "           {'label':'ORG','id':'BB','pattern':'$BB'},\n",
    "           {'label':'ORG','id':'BB','pattern':'Blackberry'},\n",
    "           {'label':'ORG','id':'GME','pattern':'GME'},\n",
    "           {'label':'ORG','id':'GME','pattern':'$GME'},\n",
    "            {'label':'ORG','id':'GME','pattern':[{'lower':'gme'}]},\n",
    "           {'label':'ORG','id':'GME','pattern':[{'lower':'gamestop'}]},\n",
    "           {'label':'ORG','id':'GME','pattern':[{'lower':'game'},{'lower':'stop'}]},\n",
    "           {'label':'ORG','id':'RTX','pattern':[{'lower':'raytheon'}]},\n",
    "           {'label':'ORG','id':'NIO','pattern':'NIO'},\n",
    "           {'label':'ORG','id':'AAPL','pattern':'AAPL'},\n",
    "           {'label':'ORG','id':'BP','pattern':'BP'},\n",
    "           {'label':'ORG','id':'BEAM','pattern':'BEAM'},\n",
    "           {'label':'ORG','id':'POWW','pattern':'POWW'},\n",
    "           {'label':'ORG','id':'POWW','pattern':[{'lower':'ammo munitions'}]},\n",
    "           {'label':'ORG','id':'SPY','pattern':'SPY'},\n",
    "           {'label':'ORG','id':'QQQ','pattern':'QQQ'},\n",
    "           {'label':'ORG','id':'BB','pattern':'BB'},\n",
    "           {'label':'ORG','id':'ATVI','pattern':[{'lower':'activision'}]},\n",
    "           {'label':'ORG','id':'AMC','pattern':'AMC'},\n",
    "           {'label':'ORG','id':'AMC','pattern':'$AMC'},\n",
    "           {'label':'PERSON','id':'Elon_Musk','pattern':[{'lower':'elon musk'}]},\n",
    "           {'label':'PERSON','id':'Elon_Musk','pattern':[{'lower':'elon'}]},\n",
    "            {'label':'ORG','id':'Robinhood','pattern':[{'lower':'robinhood'}]},\n",
    "           {'label':'ORG','id':'Melvin_Capital','pattern':[{'lower':'melvin'}]},\n",
    "           {'label':'ORG','id':'Melvin_Capital','pattern':[{'lower':'melvin capital',}]}]\n",
    "                     \n",
    "ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out_wsb = pd.DataFrame()\n",
    "\n",
    "for item in df_wsb['title']:\n",
    "    df_out_wsb = df_out_wsb.append([[item,[(ent.text, ent.label_, ent.ent_id_) for ent in nlp(item).ents]]],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AMC', 'BB', 'GME', 'Melvin_Capital', 'Robinhood'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(str(list(df_wsb['title'])))\n",
    "set([ent.ent_id_ for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automating NER\n",
    "# The idea : we can use the manually annotated examples to train the model to generalise\n",
    "train_data = []\n",
    "\n",
    "for i in df_wsb['title']:\n",
    "    doc = nlp(i)\n",
    "    if doc.ents == ():# or 'PERSON' in [ent.label_ for ent in doc.ents]:\n",
    "        continue\n",
    "    else:\n",
    "        train_data.append((doc.text, {'entities':[(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('GME; when diamonds break (missing another 25k loss expired last week)',\n",
       "  {'entities': [(0, 3, 'ORG')]}),\n",
       " ('Summary of all $BB (BlackBerry) fundamentals/news',\n",
       "  {'entities': [(15, 18, 'ORG')]}),\n",
       " ('Here‚Äôs to all the Karen‚Äôs in the world. GME 20K to 1.35 million.',\n",
       "  {'entities': [(40, 43, 'ORG')]}),\n",
       " ('Autist Rich Asian: Ape bought $10M of GME near its peak ($8M Loss)',\n",
       "  {'entities': [(38, 41, 'ORG')]}),\n",
       " ('A Good Point About the Squeeze and GME', {'entities': [(35, 38, 'ORG')]}),\n",
       " ('GME gains! Still holding my shares invested 10 thousand into GME calls, sold them and bought shares. Still holdingüôåüèΩüíéüöÄüöÄ',\n",
       "  {'entities': [(0, 3, 'ORG'), (61, 64, 'ORG')]}),\n",
       " ('‚ÄúWhat to do if you lost money on GameStop, AMC, or other ‚Äòmeme stocks‚Äô ‚Äú',\n",
       "  {'entities': [(33, 41, 'ORG'), (43, 46, 'ORG')]}),\n",
       " ('DFV vs Melvin and Robinhood live',\n",
       "  {'entities': [(7, 13, 'ORG'), (18, 27, 'ORG')]}),\n",
       " ('Why no GME daily?', {'entities': [(7, 10, 'ORG')]}),\n",
       " ('People thinking there going to find the next GME and AMC',\n",
       "  {'entities': [(45, 48, 'ORG'), (53, 56, 'ORG')]}),\n",
       " (\"Robinhood's 1099 are crap\", {'entities': [(0, 9, 'ORG')]}),\n",
       " ('Reading into Blackberry‚Äôs CEO', {'entities': [(13, 23, 'ORG')]}),\n",
       " ('First trade of my life: Buy GME at $90, sell at $420.69. Am I doing it right?',\n",
       "  {'entities': [(28, 31, 'ORG')]}),\n",
       " ('GME price action DD: making higher lows and turning an ancient resistance into support',\n",
       "  {'entities': [(0, 3, 'ORG')]}),\n",
       " ('The GME shit in summary', {'entities': [(4, 7, 'ORG')]}),\n",
       " ('GME Hold and GME Paying their Debts.',\n",
       "  {'entities': [(0, 3, 'ORG'), (13, 16, 'ORG')]}),\n",
       " ('GameStop Integrating a Digital Currency Rewards Program??',\n",
       "  {'entities': [(0, 8, 'ORG')]})]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define blank model\n",
    "nlp_new = spacy.blank(\"en\")\n",
    "nlp_new.add_pipe(nlp.create_pipe(\"ner\"))\n",
    "optimizer = nlp_new.begin_training()\n",
    "\n",
    "ner = nlp_new.get_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add labels to the ner\n",
    "for text, annotations in train_data:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])\n",
    "\n",
    "# Disable pipeline components you dont need to change\n",
    "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "unaffected_pipes = [pipe for pipe in nlp_new.pipe_names if pipe not in pipe_exceptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 160.5536470413208}\n",
      "Losses {'ner': 10.942262220514143}\n",
      "Losses {'ner': 3.0904119430763113}\n",
      "Losses {'ner': 10.914622277471315}\n",
      "Losses {'ner': 5.462289057420412}\n",
      "Losses {'ner': 6.6673328495690924}\n",
      "Losses {'ner': 2.622239871258939}\n",
      "Losses {'ner': 3.7714145323942754}\n",
      "Losses {'ner': 5.585490543630312}\n",
      "Losses {'ner': 3.9166674931373255}\n",
      "Losses {'ner': 4.834412276791437}\n",
      "Losses {'ner': 6.250329318020694}\n",
      "Losses {'ner': 5.916722903445263}\n",
      "Losses {'ner': 9.156419811223525}\n",
      "Losses {'ner': 4.762985384347395}\n",
      "Losses {'ner': 5.750000292260883}\n",
      "Losses {'ner': 2.0518293408628687}\n",
      "Losses {'ner': 3.166668680058284}\n",
      "Losses {'ner': 2.000040887850652}\n",
      "Losses {'ner': 4.282306153280359}\n"
     ]
    }
   ],
   "source": [
    "# Import requirements\n",
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "from pathlib import Path\n",
    "\n",
    "# Training the model\n",
    "with nlp_new.disable_pipes(*unaffected_pipes):\n",
    "\n",
    "  # Training for 100 iterations\n",
    "  for iteration in range(100):\n",
    "\n",
    "    # shuffling examples  before every iteration\n",
    "    random.shuffle(train_data)\n",
    "    losses = {}\n",
    "    # batch up the examples using spaCy's minibatch\n",
    "    batches = minibatch(train_data, size=compounding(4.0, 32.0, 1.001))\n",
    "    for batch in batches:\n",
    "        texts, annotations = zip(*batch)\n",
    "        nlp_new.update(\n",
    "                    texts,  # batch of texts\n",
    "                    annotations,  # batch of annotations\n",
    "                    sgd=optimizer,\n",
    "                    drop=0.1,  # dropout - make it harder to memorise data\n",
    "                    losses=losses,\n",
    "                )\n",
    "    if iteration % 5 == 0:\n",
    "        print(\"Losses\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('Robinhood', 'ORG')]\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "doc = nlp_new(\"A new retail stock trading app called Robinhood was launched\")\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('', 'ORG', 'BMW')]\n"
     ]
    }
   ],
   "source": [
    "# Check for one entity that is not in corpus\n",
    "doc = nlp_new('BMW; when diamonds break (missing another 25k loss expired last week)')\n",
    "print(\"Entities\", [(ruler.matcher.vocab.strings[ent.ent_id], ent.label_, ent.text) for ent in doc.ents])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
